---
title: 数学基础
outline: deep
---

# 数学基础

$$
x = {-b \pm \sqrt{b^2-4ac} \over 2a}
$$

## 线性代数

### 张量(tensor)

就像**向量**是**标量**的推广，**矩阵**是向量的推广一样，我们可以构建具有更多轴的数据结构。

向量是一阶张量，矩阵是二阶张量。 张量用特殊字体的大写字母表示。

### 范数(norm)

线性代数中最有用的一些运算符是范数。 非正式地说，向量的范数是表示一个向量有多大。 这里考虑的大小（size）概念不涉及维度，而是分量的大小。

- **L1 范数**，是向量元素**绝对值之和**。

- **L2 范数**，是向量元素**平方和的平方根**。L2 常省略下标 2，即 $\scriptstyle\| X \|$ 等同于 $\scriptstyle\| X \|_2$。

## 微积分(导数-梯度)

### 为毛叫「微积分」

从微积分基本定理可以看出，积分和微分实际上是逆过程：
:::tip

- 微分是通过局部的变化率来描述函数的行为。
- 积分是通过累积这些局部的变化（面积）来得到总体的行为。
  :::

将微分和积分联系起来的基本定理显示了它们是相辅相成的，解决问题时经常需要同时使用。

比如，解决一个运动问题，可能需要`先用微分来描述速度，然后用积分来计算距离`。因此，在数学中，这两个操作结合起来被称为「微积分」。

**微分**和**积分**是微积分的两个分支，**微分**可以应用于深度学习中的**优化**问题。

**导数**可以被解释为函数相对于其变量的**瞬时变化率(速度)**，它也是函数曲线的**切线的斜率**。

**梯度**是一个**向量**，其分量是多变量函数相对于其所有变量的**偏导数**。

**链式法则**，可以用来微分复合函数。

### 自动微分

虽然求导的计算很简单，只需要一些基本的微积分。 但对于复杂的模型，手工进行更新是一件很痛苦的事情（而且经常容易出错）。

深度学习框架通过自动计算导数，即**自动微分**（`automatic differentiation`）来加快求导。 实际中，根据设计好的模型，系统会构建一个**计算图**（`computational graph`）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。 自动微分使系统能够随后反向传播梯度。 这里，**反向传播**（`backpropagate`）意味着跟踪整个计算图，填充关于每个参数的**偏导数**。

## 概率

简单地说，机器学习就是做出预测。

在强化学习中，我们希望智能体（agent）能在一个环境中智能地行动。 这意味着我们需要考虑在每种可行的行为下获得高奖励的概率。

从概率分布中抽取样本的过程称为抽样（sampling）。 笼统来说，可以把分布（distribution）看作对事件的概率分配，将概率分配给一些离散选择的分布称为多项分布（multinomial distribution）。

### 联合概率

$$
P(A = a, B = b) \leq P(A = a)
$$

### 条件概率

$$
0 \leq \frac{P(A - a, B - b)}{P(A - a)} \leq 1
$$

### 贝叶斯定理

Bayes 定理（Bayes’ theorem）。
$$
P(A | B) = \frac{P(B | A)P(A)}{P(B)}
$$

### 边际化

为了能进行事件概率求和，我们需要求和法则（sum rule）， 即 $B$ 的概率相当于计算 $A$ 的所有可能选择，并将所有选择的联合概率聚合在一起：
$$
P(B) = \sum_A P(A, B)
$$
这也称为边际化（marginalization）。 边际化结果的概率或分布称为边际概率（marginal probability） 或边际分布（marginal distribution）。

### 期望和方差

数学期望(Expected Value)用来描述随机变量在长期试验中的**平均表现**，可以理解为「理论上长期重复实验的平均结果」。一个随机变量 $X$ 的期望（expectation，或平均值（average））表示为：
$$
E[X] = \sum_x xP(X = x)
$$

##### 直观理解

假设你掷一个公平的六面骰子无数次，每次的点数（1 到 6）出现的概率都是 1/6。那么长期的平均点数就是：
$$
\frac{1+2+3+4+5+6}{6} = 3.5
$$
这里的 **3.5** 就是骰子的数学期望。

##### 数学定义

对于**离散型随机变量**（取值可列举）：
$$
E(X) = \sum_i x_i \cdot P(X=x_i)
$$
即所有可能值 $x_i$ 乘以其概率后求和。

当函数 $g(x)$ 的输入是从分布 $P$ 中抽取的离散随机变量时，期望值为：
$$
E_{x \sim P}[g(x)] = \sum_{x} g(x)P(x)
$$

对于**连续型随机变量**（取值不可列举）：
$$
E(X) = \int_{-\infty}^{\infty} x \cdot f(x)dx
$$
其中 $f(x)$ 是概率密度函数。

当函数 $g(x)$ 的输入是从分布 $P$ 中抽取的连续随机变量，期望值公式会改为积分形式：
$$
E_{x \sim P}[g(x)] = \int g(x)P(x)dx
$$

**方差**：衡量随机变量 $X$ 与其期望值的偏置，可通过方差来量化：
$$
Var[X] = E[(X - E[X])^2] = E[X^2] - E[X]^2
$$
随机变量函数的方差衡量的是：当从该随机变量分布中采样不同值 $x$ 时，函数值偏离该函数的期望的程度：
$$
Var[f(x)] = E[(f(x) - E[f(x)])^2]
$$

方差的平方根被称为标准差（standard deviation）。

##### 期望举例

1. **彩票问题**：  
   一张彩票有 1/100 的概率中奖 100 元，否则得 0 元。期望收益：
   $$
   E(X) = 100 \times \frac{1}{100} + 0 \times \frac{99}{100} = 1 \text{元}
   $$
   这意味着长期买彩票，平均每次“赚”1 元（但实际中彩票期望常低于成本）。

2. **投资决策**：  
   若投资 A 有 50%概率赚 10 万，50%概率亏 5 万，期望收益：
   $$
   E(X) = 10 \times 0.5 + (-5) \times 0.5 = 2.5 \text{万}
   $$
   这比确定性收益 2 万更“划算”（但实际需结合风险偏好）。

##### 关键性质

- **线性性**：$E(aX + bY) = aE(X) + bE(Y)$，即使变量不独立。
- **独立性**：若 $X,Y$ 独立，则 $E(XY) = E(X)E(Y)$。

##### 注意

- 期望不一定属于随机变量的可能取值（如骰子期望 3.5，但实际只能掷出整数）。
- 期望反映的是长期趋势，单次结果可能差异极大。

理解期望能帮助理性评估风险与收益，是保险、金融、机器学习等领域的基础工具。

## 欧拉公式

欧拉公式<sup>Euler's Formula</sup>是数学中一个非常著名的公式，它将**复数、指数函数和三角函数**联系在一起。欧拉公式的常见形式如下：

$$
e^{i\theta} = \cos\theta + i\sin\theta
$$

其中：

- $e$ 是自然对数的底（约等于 2.71828）。
- $i$ 是虚数单位，满足 $i^2 = -1$。
- $\theta$ 是一个实数，表示角度（通常以弧度为单位）。
- $\cos\theta$ 和 $\sin\theta$ 分别是角度 $\theta$ 的余弦和正弦函数。

### 数学证明

欧拉公式可以通过**泰勒级数**展开来证明：

1. 指数函数 $e^x$ 的泰勒展开：
   $$
   e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots
   $$
2. 将 $x = i\theta$ 代入，并利用 $i^2 = -1$、$i^3 = -i$、$i^4 = 1$ 等性质，可以得到：
   $$
   e^{i\theta} = 1 + i\theta - \frac{\theta^2}{2!} - i\frac{\theta^3}{3!} + \frac{\theta^4}{4!} + \cdots
   $$
3. 将实部和虚部分开：
   $$
   e^{i\theta} = \left(1 - \frac{\theta^2}{2!} + \frac{\theta^4}{4!} - \cdots\right) + i\left(\theta - \frac{\theta^3}{3!} + \frac{\theta^5}{5!} - \cdots\right)
   $$
4. 注意到这两个级数分别是 $\cos\theta$ 和 $\sin\theta$ 的泰勒展开，因此：
   $$
   e^{i\theta} = \cos\theta + i\sin\theta
   $$

### 恒等式

当 $\theta = \pi$ 时，欧拉公式变为：

$$
e^{i\pi} + 1 = 0
$$

这就是著名的**欧拉恒等式**<sup>Euler's Identity</sup>，它包含了数学中五个最重要的常数：$0, 1, e, i, \pi$，被誉为“数学中最美的公式”。

### 几何意义

欧拉公式表明，复数 $e^{i\theta}$ 在复平面上对应的是**一个单位圆上的点**，其横坐标为 $\cos\theta$，纵坐标为 $\sin\theta$。因此，欧拉公式实际上描述了复平面上单位圆的参数方程。

当 $\theta$ 变化时，$e^{i\theta}$ 沿着单位圆旋转。

- $e^{i0} = 1$（角度 0，指向正右方）
- $e^{i\pi/2} = i$（角度 90°，指向上方）
- $e^{i\pi} = -1$（角度 180°，指向左方）
- $e^{i3\pi/2} = -i$（角度 270°，指向下方）

[**复数旋转**](/aiart/deep-learning/gpt.html#复数旋转)：$e^{i\theta}$ 复指数函数不仅仅是一个数学符号，天然包含**旋转**信息，是**旋转在复数世界里的自然表达**。

### 应用领域

欧拉公式在数学、物理和工程中有广泛的应用，例如：

1. **复数运算**：简化复数的乘除和幂运算。
2. **信号处理**：傅里叶变换和频域分析中常用欧拉公式表示正弦波。
3. **微分方程**：求解常系数线性微分方程时，欧拉公式可以帮助找到复数形式的解。
4. **量子力学**：波函数的描述中经常用到欧拉公式。

欧拉公式是连接不同数学分支的重要桥梁，展现了**数学的深刻统一性**。
