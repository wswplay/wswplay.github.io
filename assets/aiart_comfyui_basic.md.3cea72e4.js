import{_ as e,c as a,o as i,a as r}from"./app.ff132c15.js";const _=JSON.parse('{"title":"ComfyUI","description":"","frontmatter":{"title":"ComfyUI"},"headers":[{"level":2,"title":"VAE(变分自编码器)","slug":"vae-变分自编码器","link":"#vae-变分自编码器","children":[{"level":3,"title":"总结","slug":"总结","link":"#总结","children":[]}]},{"level":2,"title":"CLIP-(对比式语言-图像预训练)","slug":"clip-对比式语言-图像预训练","link":"#clip-对比式语言-图像预训练","children":[{"level":3,"title":"总结","slug":"总结-1","link":"#总结-1","children":[]}]},{"level":2,"title":"LoRA-低秩自适应","slug":"lora-低秩自适应","link":"#lora-低秩自适应","children":[{"level":3,"title":"核心思想","slug":"核心思想","link":"#核心思想","children":[]},{"level":3,"title":"工作原理","slug":"工作原理","link":"#工作原理","children":[]}]}],"relativePath":"aiart/comfyui/basic.md"}'),t={name:"aiart/comfyui/basic.md"},l=r('<h1 id="your-creativity-we-visualed" tabindex="-1">Your creativity, We Visualed！ <a class="header-anchor" href="#your-creativity-we-visualed" aria-hidden="true">#</a></h1><h2 id="vae-变分自编码器" tabindex="-1">VAE(变分自编码器) <a class="header-anchor" href="#vae-变分自编码器" aria-hidden="true">#</a></h2><p>VAE(<code>Variational Autoencoder</code>) 是一种生成模型，包含两个主要部分：编码器（Encoder）和解码器（Decoder）。</p><h3 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-hidden="true">#</a></h3><ul><li><strong>编码器</strong>：将数据映射到潜在空间。</li><li><strong>解码器</strong>：从潜在空间生成数据。</li><li><strong>目标</strong>：学习数据的低维表示并生成新数据。</li></ul><h2 id="clip-对比式语言-图像预训练" tabindex="-1">CLIP-(对比式语言-图像预训练) <a class="header-anchor" href="#clip-对比式语言-图像预训练" aria-hidden="true">#</a></h2><p>CLIP（<code>Contrastive Language–Image Pretraining</code>）是 OpenAI 提出的一种多模态模型，用于将图像和文本映射到同一个语义空间。与 VAE 不同，CLIP 没有传统意义上的“编码器”和“解码器”，而是由两个核心组件组成：<strong>图像编码器</strong>和<strong>文本编码器</strong>。</p><h3 id="总结-1" tabindex="-1">总结 <a class="header-anchor" href="#总结-1" aria-hidden="true">#</a></h3><p>CLIP 的“编码器”包括图像编码器和文本编码器，它们分别将图像和文本映射到同一个语义空间。CLIP 没有传统意义上的“解码器”，而是通过对比学习实现图像和文本的语义对齐。CLIP 的核心优势在于其强大的多模态理解能力，能够广泛应用于图像-文本检索、零样本分类等任务。</p><h2 id="lora-低秩自适应" tabindex="-1">LoRA-低秩自适应 <a class="header-anchor" href="#lora-低秩自适应" aria-hidden="true">#</a></h2><p>LoRA（Low-Rank Adaptation）是一种用于<strong>微调</strong>大型预训练模型的技术，旨在高效适应特定任务，同时减少计算和存储开销。</p><h3 id="核心思想" tabindex="-1">核心思想 <a class="header-anchor" href="#核心思想" aria-hidden="true">#</a></h3><p>LoRA 通过在预训练模型的权重矩阵中引入低秩矩阵来实现微调，避免直接修改原始权重，从而降低资源需求。</p><h3 id="工作原理" tabindex="-1">工作原理 <a class="header-anchor" href="#工作原理" aria-hidden="true">#</a></h3><ul><li><strong>低秩分解</strong>：将权重矩阵分解为两个较小的矩阵，近似表示原始矩阵。</li><li><strong>参数更新</strong>：仅更新这些低秩矩阵，而非整个权重矩阵，减少可训练参数数量。</li></ul>',15),n=[l];function o(d,s,c,h,u,g){return i(),a("div",null,n)}const f=e(t,[["render",o]]);export{_ as __pageData,f as default};
