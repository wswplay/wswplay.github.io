import{_ as o,c as e,o as t,b as n}from"./chunks/framework._eNwL97Z.js";const s="/assets/transformer.C26fAZXE.svg",f=JSON.parse('{"title":"Transformer","description":"","frontmatter":{"title":"Transformer","outline":"deep"},"headers":[{"level":2,"title":"模型","slug":"模型","link":"#模型","children":[]}],"relativePath":"aiart/deep-learning/transformer.md","filePath":"aiart/deep-learning/transformer.md"}'),a={name:"aiart/deep-learning/transformer.md"};function i(d,r,g,l,c,p){return t(),e("div",null,r[0]||(r[0]=[n('<h1 id="transformer-架构" tabindex="-1">Transformer 架构 <a class="header-anchor" href="#transformer-架构" aria-label="Permalink to &quot;Transformer 架构&quot;">​</a></h1><p>自注意力同时具有<strong>并行计算</strong>和<strong>最短最大路径长度</strong>这两个优势，因此使用自注意力来设计深度架构是很有吸引力的。</p><p><code>Transformer</code> 模型<strong>完全基于注意力机制</strong>，没有任何卷积层或循环神经网络层。</p><p>尽管 Transformer 最初是应用于在<strong>文本数据</strong>上的序列到序列学习，但现在已经推广到各种现代的深度学习中，例如<strong>语言、视觉、语音和强化学习</strong>领域。</p><h2 id="模型" tabindex="-1">模型 <a class="header-anchor" href="#模型" aria-label="Permalink to &quot;模型&quot;">​</a></h2><p><img src="'+s+'" alt="An Image"> Transformer 是<strong>编码器－解码器</strong>架构实例，基于<strong>自注意力模块叠加</strong>而成。</p><p><strong>源序列</strong>（输入）嵌入（<code>embedding</code>），和<strong>目标序列</strong>（输出）嵌入加上<strong>位置编码</strong>（<code>positional encoding</code>），分别输入到编码器和解码器中。</p><p><strong>编码器</strong>：由多个相同的层叠加而成的，每个层都有两个子层（子层表示为 <code>sublayer</code>）。</p><ul><li>第一个子层：<strong>多头自注意力</strong>（<code>multi-head self-attention</code>）汇聚；</li><li>第二个子层：<strong>基于位置的前馈网络</strong>（<code>positionwise feed-forward network</code>）。</li><li>具体计算时，查询、键和值都<strong>来自前一个编码器</strong>层的输出，每个子层都采用了<strong>残差连接</strong>（<code>residual connection</code>），在残差连接的加法计算之后，紧接着应用<strong>层规范化</strong>（<code>layer normalization</code>）。</li></ul><p><strong>解码器</strong>：也是由多个相同的层叠加而成的，并且层中使用了残差连接和层规范化。</p>',10)]))}const _=o(a,[["render",i]]);export{f as __pageData,_ as default};
