import{_ as s,c as n,o as a,a as l}from"./app.f57e7a55.js";const C=JSON.parse('{"title":"ComfyUI","description":"","frontmatter":{"title":"ComfyUI","outline":"deep"},"headers":[{"level":2,"title":"VAE(变分自编码器)","slug":"vae-变分自编码器","link":"#vae-变分自编码器","children":[{"level":3,"title":"总结","slug":"总结","link":"#总结","children":[]}]},{"level":2,"title":"CLIP-(对比式语言-图像预训练)","slug":"clip-对比式语言-图像预训练","link":"#clip-对比式语言-图像预训练","children":[{"level":3,"title":"总结","slug":"总结-1","link":"#总结-1","children":[]},{"level":3,"title":"代码实现","slug":"代码实现","link":"#代码实现","children":[]}]},{"level":2,"title":"LoRA-低秩自适应","slug":"lora-低秩自适应","link":"#lora-低秩自适应","children":[{"level":3,"title":"核心思想","slug":"核心思想","link":"#核心思想","children":[]},{"level":3,"title":"工作原理","slug":"工作原理","link":"#工作原理","children":[]}]}],"relativePath":"aiart/comfyui/basic.md"}'),p={name:"aiart/comfyui/basic.md"},o=l(`<h1 id="your-creativity-we-visualed" tabindex="-1">Your creativity, We Visualed！ <a class="header-anchor" href="#your-creativity-we-visualed" aria-hidden="true">#</a></h1><h2 id="vae-变分自编码器" tabindex="-1">VAE(变分自编码器) <a class="header-anchor" href="#vae-变分自编码器" aria-hidden="true">#</a></h2><p>VAE(<code>Variational Autoencoder</code>) 是一种生成模型，包含两个主要部分：编码器（Encoder）和解码器（Decoder）。</p><h3 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-hidden="true">#</a></h3><ul><li><strong>编码器</strong>：将数据映射到潜在空间。</li><li><strong>解码器</strong>：从潜在空间生成数据。</li><li><strong>目标</strong>：学习数据的低维表示并生成新数据。</li></ul><h2 id="clip-对比式语言-图像预训练" tabindex="-1">CLIP-(对比式语言-图像预训练) <a class="header-anchor" href="#clip-对比式语言-图像预训练" aria-hidden="true">#</a></h2><p>CLIP（<code>Contrastive Language–Image Pretraining</code>）是 OpenAI 提出的一种多模态模型，用于将图像和文本映射到同一个语义空间。与 VAE 不同，CLIP 没有传统意义上的“编码器”和“解码器”，而是由两个核心组件组成：<strong>图像编码器</strong>和<strong>文本编码器</strong>。</p><h3 id="总结-1" tabindex="-1">总结 <a class="header-anchor" href="#总结-1" aria-hidden="true">#</a></h3><p>CLIP 的“编码器”包括图像编码器和文本编码器，它们分别将图像和文本映射到同一个语义空间。CLIP 没有传统意义上的“解码器”，而是通过对比学习实现图像和文本的语义对齐。CLIP 的核心优势在于其强大的多模态理解能力，能够广泛应用于图像-文本检索、零样本分类等任务。</p><h3 id="代码实现" tabindex="-1">代码实现 <a class="header-anchor" href="#代码实现" aria-hidden="true">#</a></h3><p>下面是一个简单的代码示例，使用 <strong>OpenAI 的 CLIP 模型</strong> 来实现文本和图像的嵌入计算，并计算它们之间的相似度。我们将使用 Hugging Face 的 <code>transformers</code> 库和 OpenAI 的 <code>clip</code> 库来实现。</p><hr><p><strong>环境准备</strong></p><p>首先，安装所需的库：</p><div class="language-bash line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#FFCB6B;">pip</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">install</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">torch</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">torchvision</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">transformers</span><span style="color:#A6ACCD;"> </span><span style="color:#C3E88D;">clip</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><hr><p><strong>代码实现</strong></p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> torch</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> clip</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> PIL </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> Image</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> requests</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">from</span><span style="color:#A6ACCD;"> io </span><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> BytesIO</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 加载CLIP模型和预处理函数</span></span>
<span class="line"><span style="color:#A6ACCD;">device </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">cuda</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">cuda</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">is_available</span><span style="color:#89DDFF;">()</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;font-style:italic;">else</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">cpu</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"><span style="color:#A6ACCD;">model</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> preprocess </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> clip</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">load</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">ViT-B/32</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#A6ACCD;font-style:italic;">device</span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;">device</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 示例文本</span></span>
<span class="line"><span style="color:#A6ACCD;">texts </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">a photo of a cat</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">a photo of a dog</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">a photo of a mountain</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 示例图像（从网络加载）</span></span>
<span class="line"><span style="color:#A6ACCD;">image_url </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">https://example.com/path/to/your/image.jpg</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;font-style:italic;"># 替换为你的图片URL</span></span>
<span class="line"><span style="color:#A6ACCD;">response </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> requests</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">get</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">image_url</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">image </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> Image</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">open</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">BytesIO</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">response</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">content</span><span style="color:#89DDFF;">)).</span><span style="color:#82AAFF;">convert</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">RGB</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 预处理图像和文本</span></span>
<span class="line"><span style="color:#A6ACCD;">image_input </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">preprocess</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">image</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">unsqueeze</span><span style="color:#89DDFF;">(</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">to</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">device</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">text_inputs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> clip</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">tokenize</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">texts</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">to</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">device</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 计算图像和文本的特征嵌入</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">with</span><span style="color:#A6ACCD;"> torch</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">no_grad</span><span style="color:#89DDFF;">():</span></span>
<span class="line"><span style="color:#A6ACCD;">    image_features </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">encode_image</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">image_input</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">    text_features </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> model</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">encode_text</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">text_inputs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 计算图像和文本的相似度</span></span>
<span class="line"><span style="color:#A6ACCD;">logits_per_image</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> logits_per_text </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">image_input</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> text_inputs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">probs </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> logits_per_image</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">softmax</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">dim</span><span style="color:#89DDFF;">=-</span><span style="color:#F78C6C;">1</span><span style="color:#89DDFF;">).</span><span style="color:#82AAFF;">cpu</span><span style="color:#89DDFF;">().</span><span style="color:#82AAFF;">numpy</span><span style="color:#89DDFF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 输出结果</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Image features shape:</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> image_features</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Text features shape:</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> text_features</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">shape</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Similarity probabilities:</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> probs</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># 打印最匹配的文本</span></span>
<span class="line"><span style="color:#A6ACCD;">best_match_idx </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> probs</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">argmax</span><span style="color:#89DDFF;">()</span></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;Best match: &#39;</span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">texts</span><span style="color:#89DDFF;">[</span><span style="color:#82AAFF;">best_match_idx</span><span style="color:#89DDFF;">]</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;">&#39; with probability </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">probs</span><span style="color:#89DDFF;">[</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">][</span><span style="color:#82AAFF;">best_match_idx</span><span style="color:#89DDFF;">]</span><span style="color:#C792EA;">:.4f</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br></div></div><hr><p><strong>代码说明</strong></p><ol><li><p><strong>加载模型</strong>：</p><ul><li>使用 <code>clip.load(&quot;ViT-B/32&quot;)</code> 加载 CLIP 模型和预处理函数。</li><li><code>ViT-B/32</code> 是一个基于 Vision Transformer 的 CLIP 模型，适合大多数任务。</li></ul></li><li><p><strong>输入数据</strong>：</p><ul><li>文本：<code>texts</code> 是一个包含多个文本描述的列表。</li><li>图像：从网络加载一张图像，并使用 <code>preprocess</code> 函数进行预处理。</li></ul></li><li><p><strong>特征嵌入</strong>：</p><ul><li>使用 <code>model.encode_image</code> 计算图像的特征嵌入。</li><li>使用 <code>model.encode_text</code> 计算文本的特征嵌入。</li></ul></li><li><p><strong>相似度计算</strong>：</p><ul><li>使用 <code>model(image_input, text_inputs)</code> 计算图像和文本的相似度。</li><li>通过 <code>softmax</code> 将相似度转换为概率。</li></ul></li><li><p><strong>结果输出</strong>：</p><ul><li>输出图像和文本的特征嵌入形状。</li><li>输出图像与每个文本的相似度概率。</li><li>输出最匹配的文本描述。</li></ul></li></ol><hr><p><strong>示例输出</strong></p><p>假设输入图像是一只猫，输出可能如下：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#A6ACCD;">Image features shape: (1, 512)</span></span>
<span class="line"><span style="color:#A6ACCD;">Text features shape: (3, 512)</span></span>
<span class="line"><span style="color:#A6ACCD;">Similarity probabilities: [[0.95 0.03 0.02]]</span></span>
<span class="line"><span style="color:#A6ACCD;">Best match: &#39;a photo of a cat&#39; with probability 0.9500</span></span>
<span class="line"><span style="color:#A6ACCD;"></span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><p><strong>总结</strong></p><ul><li>这段代码展示了如何使用 CLIP 模型计算图像和文本的嵌入，并计算它们之间的相似度。</li><li>你可以替换图像和文本输入，尝试不同的任务，例如图像分类、文本-图像检索等。</li><li>CLIP 的强大之处在于它能够将图像和文本映射到同一语义空间，从而实现跨模态的理解和匹配。</li></ul><h2 id="lora-低秩自适应" tabindex="-1">LoRA-低秩自适应 <a class="header-anchor" href="#lora-低秩自适应" aria-hidden="true">#</a></h2><p>LoRA（Low-Rank Adaptation）是一种用于<strong>微调</strong>大型预训练模型的技术，旨在高效适应特定任务，同时减少计算和存储开销。</p><h3 id="核心思想" tabindex="-1">核心思想 <a class="header-anchor" href="#核心思想" aria-hidden="true">#</a></h3><p>LoRA 通过在预训练模型的权重矩阵中引入低秩矩阵来实现微调，避免直接修改原始权重，从而降低资源需求。</p><h3 id="工作原理" tabindex="-1">工作原理 <a class="header-anchor" href="#工作原理" aria-hidden="true">#</a></h3><ul><li><strong>低秩分解</strong>：将权重矩阵分解为两个较小的矩阵，近似表示原始矩阵。</li><li><strong>参数更新</strong>：仅更新这些低秩矩阵，而非整个权重矩阵，减少可训练参数数量。</li></ul>`,34),e=[o];function t(r,c,i,F,D,y){return a(),n("div",null,e)}const u=s(p,[["render",t]]);export{C as __pageData,u as default};
